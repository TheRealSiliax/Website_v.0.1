https://www.reddit.com/r/PromptEngineering/s/CIhEPHxYBY 

follow/ PN creator & give Credits! 

The Ultimate Prompt Engineering Framework: Building a Structured AI Team with the SPARC 
System 

*How I created a multi-agent system with advanced prompt engineering techniques that 
dramatically improves AI performance* 

## Introduction: Why Standard Prompting Falls Short 

After experimenting extensively with AI assistants like Roo Code, I discovered that their true 
potential isn't unlocked through basic prompting. The real breakthrough came when I developed 
a structured prompt engineering system that implements specialized agents, each with carefully 
crafted prompt templates and interaction patterns. 

The framework I'm sharing today uses advanced prompt engineering to create specialized AI 
personas (Orchestrator, Research, Code, Architect, Debug, Ask, Memory) that operate through 
what I call the SPARC framework: 

- **S**tructured prompts with standardized sections 
- **P**rimitive operations that combine into cognitive processes 
- **A**gent specialization with role-specific context 
- **R**ecursive boomerang pattern for task delegation 
- **C**ontext management for token optimization 

## The Prompt Architecture: How It All Connects 

This diagram illustrates how the entire prompt engineering system works. Each box represents 
a component with carefully designed prompt patterns: 

``` 
┌─────────────────────────────────┐ 
│            VS Code              │ 
│     (Primary Development        │ 
│          Environment)           │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐ 
│             Roo Code            │ 
│                ↓                │ 

 
 
 
 
 
 
 
 
 
 
 
│          System Prompt          │ 
│   (Contains SPARC Framework:    │ 
│    • Specification, Pseudocode, │ 
│      Architecture, Refinement,  │ 
│      Completion methodology     │ 
│    • Advanced reasoning models  │ 
│    • Best practices enforcement │ 
│    • Memory Bank integration    │ 
│    • Boomerang pattern support) │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐      
┌─────────────────────────┐ 
│           Orchestrator          │      │         User            │ 
│     (System Prompt contains:    │      │     (Customer with      │ 
│      roles, definitions,        │◄─────┤     minimal context)    │ 
│      systems, processes,        │      │                         │ 
│      nomenclature, etc.)        │      └─────────────────────────┘ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐ 
│        Query Processing         │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐ 
│         MCP → Reprompt          │ 
│     (Only called on direct      │ 
│         user input)             │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐ 
│     Structured Prompt Creation  │ 
│                                 │ 
│       Project Prompt Eng.       │ 
│       Project Context           │ 
│       System Prompt             │ 
│       Role Prompt               │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 

┌─────────────────────────────────┐ 
│           Orchestrator          │ 
│     (System Prompt contains:    │ 
│      roles, definitions,        │ 
│      systems, processes,        │ 
│      nomenclature, etc.)        │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐ 
│         Substack Prompt         │ 
│   (Generated by Orchestrator    │ 
│        with structure)          │ 
│                                 │ 
│    ┌─────────┐  ┌─────────┐    │ 
│    │  Topic  │  │ Context │    │ 
│    └─────────┘  └─────────┘    │ 
│                                 │ 
│    ┌─────────┐  ┌─────────┐    │ 
│    │  Scope  │  │ Output  │    │ 
│    └─────────┘  └─────────┘    │ 
│                                 │ 
│    ┌─────────────────────┐     │ 
│    │       Extras        │     │ 
│    └─────────────────────┘     │ 
└───────────────┬─────────────────┘ 
                │ 
                ▼ 
┌─────────────────────────────────┐   
┌────────────────────────────────────┐ 
│       Specialized Modes         │   │           MCP Tools                 │ 
│                                 │   │                                     │ 
│  ┌────────┐ ┌────────┐ ┌─────┐ │   │ ┌─────────┐  
┌─────────────────┐   │ 
│  │  Code  │ │ Debug  │ │ ... │ │──►│ │ Basic   │  │ CLI/Shell        │   │ 
│  └────┬───┘ └────┬───┘ └──┬──┘ │   │ │ CRUD    │  │ (cmd/PowerShell) │   │ 
│       │          │        │    │   │ └─────────┘  └─────────────────┘   │ 
└───────┼──────────┼────────┼────┘   │                                     │ 
        │          │        │        │ ┌─────────┐  ┌─────────────────┐   │ 
        │          │        │        │ │ API     │  │ Browser          │   │ 
        │          │        └───────►│ │ Calls   │  │ Automation       │   │ 
        │          │                 │ │ (Alpha  │  │ (Playwright)     │   │ 
        │          │                 │ │ Vantage)│  │                  │   │ 
        │          │                 │ └─────────┘  └─────────────────┘   │ 

        │          │                 │                                     │ 
        │          └────────────────►│ ┌──────────────────────────────┐   
│ 
        │                            │ │        LLM Calls              │   │ 
        │                            │ │                               │   │ 
        │                            │ │ • Basic Queries               │   │ 
        └───────────────────────────►│ │ • Reporter Format            │   │ 
                                     │ │ • Logic MCP Primitives        │   │ 
                                     │ │ • Sequential Thinking         │   │ 
                                     │ └──────────────────────────────┘   │ 
                                     └────────────────┬─────────────────┬─┘ 
                                                      │                 │ 
                                                      ▼                 │ 
┌───────────────────────────────────────────────────────────
──────┐    │ 
│                   Recursive Loop                                │    │ 
│                                                                 │    │ 
│  ┌────────────────────────┐    ┌───────────────────────┐       │    
│ 
│  │     Task Execution     │    │      Reporting        │       │    │ 
│  │                        │    │                       │       │    │ 
│  │ • Execute assigned task│───►│ • Report work done    │       │◄───┘ 
│  │ • Solve specific issue │    │ • Share issues found  │       │ 
│  │ • Maintain focus       │    │ • Provide learnings   │       │ 
│  └────────────────────────┘    └─────────┬─────────────┘       │ 
│                                           │                     │ 
│                                           ▼                     │ 
│  ┌────────────────────────┐    ┌───────────────────────┐       │ 
│  │   Task Delegation      │    │    Deliberation       │       │ 
│  │                        │◄───┤                       │       │ 
│  │ • Identify next steps  │    │ • Assess progress     │       │ 
│  │ • Assign to best mode  │    │ • Integrate learnings │       │ 
│  │ • Set clear objectives │    │ • Plan next phase     │       │ 
│  └────────────────────────┘    └───────────────────────┘       │ 
│                                                                 │ 
└────────────────────────────────┬──────────────────────────
──────┘ 
                                 │ 
                                 ▼ 
┌───────────────────────────────────────────────────────────
──────┐ 
│                     Memory Mode                                  │ 
│                                                                 │ 
│  ┌────────────────────────┐    ┌───────────────────────┐       │ 

│  │  Project Archival      │    │   SQL Database        │       │ 
│  │                        │    │                       │       │ 
│  │ • Create memory folder │───►│ • Store project data  │       │ 
│  │ • Extract key learnings│    │ • Index for retrieval │       │ 
│  │ • Organize artifacts   │    │ • Version tracking    │       │ 
│  └────────────────────────┘    └─────────┬─────────────┘       │  
│                                           │                     | 
│                                           ▼                     │ 
│  ┌────────────────────────┐    ┌───────────────────────┐       │ 
│  │  Memory MCP            │    │   RAG System          │       │ 
│  │                        │◄───┤                       │       │ 
│  │ • Database writes      │    │ • Vector embeddings   │       │ 
│  │ • Data validation      │    │ • Semantic indexing   │       │ 
│  │ • Structured storage   │    │ • Retrieval functions │       │ 
│  └─────────────┬──────────┘    └───────────────────────┘       │ 
│                │                                               │ 
└────────────────┼──────────────────────────────────────────
─────┘ 
                 │ 
                 └───────────────────────────────────┐ 
                                    Feed             ▼ 
┌─────────────────────────────────┐ back 
┌─────────────────────────┐ 
│           Orchestrator          │ loop │         User            │ 
│     (System Prompt contains:    │      │     (Customer with      │ 
│      roles, definitions,        │◄─────┤     minimal context)    │ 
│      systems, processes,        │      │                         │ 
│      nomenclature, etc.)        │      └─────────────────────────┘ 
└───────────────┬─────────────────┘ 
| 
              Restart Recursive Loop 
``` 

## Part 1: Advanced Prompt Engineering Techniques 

### Structured Prompt Templates 

One of the key innovations in my framework is the standardized prompt template structure that 
ensures consistency and completeness: 

```markdown 
# [Task Title] 

## Context 

 
 
 
 
 
[Background information and relationship to the larger project] 

## Scope 
[Specific requirements and boundaries] 

## Expected Output 
[Detailed description of deliverables] 

## Additional Resources 
[Relevant tips or examples] 

--- 

**Meta-Information**: 
- task_id: [UNIQUE_ID] 
- assigned_to: [SPECIALIST_MODE] 
- cognitive_process: [REASONING_PATTERN] 
``` 

This template is designed to: 
- Provide complete context without redundancy 
- Establish clear task boundaries 
- Set explicit expectations for outputs 
- Include metadata for tracking 

### Primitive Operators in Prompts 

Rather than relying on vague instructions, I've identified 10 primitive cognitive operations that 
can be explicitly requested in prompts: 

1. **Observe**: "Examine this data without interpretation." 
2. **Define**: "Establish the boundaries of this concept." 
3. **Distinguish**: "Identify differences between these items." 
4. **Sequence**: "Place these steps in logical order." 
5. **Compare**: "Evaluate these options based on these criteria." 
6. **Infer**: "Draw conclusions from this evidence." 
7. **Reflect**: "Question your assumptions about this reasoning." 
8. **Ask**: "Formulate a specific question to address this gap." 
9. **Synthesize**: "Integrate these separate pieces into a coherent whole." 
10. **Decide**: "Commit to one option based on your analysis." 

These primitive operations can be combined to create more complex reasoning patterns: 

```markdown 

 
 
 
 
 
 
 
 
 
 
 
# Problem Analysis Prompt 

First, OBSERVE the problem without assumptions: 
[Problem description] 

Next, DEFINE the core challenge: 
- What is the central issue? 
- What are the boundaries? 

Then, COMPARE potential approaches using these criteria: 
- Effectiveness 
- Implementation difficulty 
- Resource requirements 

Finally, DECIDE on the optimal approach and SYNTHESIZE a plan. 
``` 

### Cognitive Process Selection in Prompts 

I've developed a matrix for selecting prompt structures based on task complexity and type: 

| Task Type | Simple | Moderate | Complex | 
|----------|--------|----------|---------| 
| Analysis | Observe → Infer | Observe → Infer → Reflect | Evidence Triangulation | 
| Planning | Define → Infer | Strategic Planning | Complex Decision-Making | 
| Implementation | Basic Reasoning | Problem-Solving | Operational Optimization | 
| Troubleshooting | Focused Questioning | Adaptive Learning | Root Cause Analysis | 
| Synthesis | Insight Discovery | Critical Review | Synthesizing Complexity | 

The difference in prompt structure for different cognitive processes is significant. For example: 

**Simple Analysis Prompt (Observe → Infer):** 
```markdown 
# Data Analysis 

## Observation 
Examine the following data points without interpretation: 
[Raw data] 

## Inference 
Based solely on the observed patterns, what conclusions can you draw? 
``` 

**Complex Analysis Prompt (Evidence Triangulation):** 

 
 
 
 
 
 
 
 
 
 
 
 
```markdown 
# Comprehensive Analysis 

## Multiple Source Observation 
Source 1: [Data set A] 
Source 2: [Data set B] 
Source 3: [Expert opinions] 

## Pattern Distinction 
Identify patterns that: 
- Appear in all sources 
- Appear in some but not all sources 
- Contradict between sources 

## Comparative Evaluation 
Compare the reliability of each source based on: 
- Methodology 
- Sample size 
- Potential biases 

## Synthesized Conclusion 
Draw conclusions supported by multiple lines of evidence, noting certainty levels. 
``` 

### Context Window Management Prompting 

I've developed a three-tier system for context loading that dramatically improves token 
efficiency: 

```markdown 
# Three-Tier Context Loading 

## Tier 1 Instructions (Always Include): 
Include only the most essential context for this task: 
- Current objective: [specific goal] 
- Immediate requirements: [critical constraints] 
- Direct dependencies: [blocking items] 

## Tier 2 Instructions (Load on Request): 
If you need additional context, specify which of these you need: 
- Background information on [topic] 
- Previous work on [related task] 
- Examples of [similar implementation] 

 
 
 
 
 
 
 
 
 
 
## Tier 3 Instructions (Exceptional Use Only): 
Request extended context only if absolutely necessary: 
- Historical decisions leading to current approach 
- Alternative approaches considered but rejected 
- Comprehensive domain background 
``` 

This tiered context management approach has been essential for working with token limitations. 

## Part 2: Specialized Agent Prompt Examples 

### Orchestrator Prompt Engineering 

The Orchestrator's prompt template focuses on task decomposition and delegation: 

```markdown 
# Orchestrator System Prompt 

You are the Orchestrator, responsible for breaking down complex tasks and delegating to 
specialists. 

## Role-Specific Instructions: 
1. Analyze tasks for natural decomposition points 
2. Identify the most appropriate specialist for each component 
3. Create clear, unambiguous task assignments 
4. Track dependencies between tasks 
5. Verify deliverable quality against requirements 

## Task Analysis Framework: 
For any incoming task, first analyze: 
- Core components and natural divisions 
- Dependencies between components 
- Specialized knowledge required 
- Potential risks or ambiguities 

## Delegation Protocol: 
When delegating, always include: 
- Clear task title 
- Complete context 
- Specific scope boundaries 
- Detailed output requirements 
- Links to relevant resources 

## Verification Standards: 

 
 
 
 
 
 
 
 
 
 
When reviewing completed work, evaluate: 
- Adherence to requirements 
- Consistency with broader project 
- Quality of implementation 
- Documentation completeness 

Always maintain the big picture view while coordinating specialized work. 
``` 

### Research Agent Prompt Engineering 

```markdown 
# Research Agent System Prompt 

You are the Research Agent, responsible for information discovery, analysis, and synthesis. 

## Information Gathering Instructions: 
1. Begin with broad exploration of the topic 
2. Identify key concepts, terminology, and perspectives 
3. Focus on authoritative, primary sources 
4. Triangulate information across multiple sources 
5. Document all sources with proper citations 

## Evaluation Framework: 
For all information, assess: 
- Source credibility and authority 
- Methodology and evidence quality 
- Potential biases or limitations 
- Consistency with other reliable sources 
- Relevance to the specific question 

## Synthesis Protocol: 
When synthesizing information: 
- Organize by themes or concepts 
- Highlight areas of consensus 
- Acknowledge contradictions or uncertainties 
- Distinguish facts from interpretations 
- Present information at appropriate technical level 

 
 
 
 
 
 
 
 
 
 
 
 
 
## Documentation Standards: 
All research outputs must include: 
- Executive summary of key findings 
- Structured presentation of detailed information 
- Clear citations for all claims 
- Limitations of the current research 
- Recommendations for further investigation 

Use Evidence Triangulation cognitive process for complex topics. 
``` 

## Part 3: Boomerang Logic in Prompt Engineering 

The boomerang pattern ensures tasks flow properly between specialized agents: 

```markdown 
# Task Assignment (Orchestrator → Specialist) 

## Task Context 
[Project background and relationship to larger goals] 

## Task Definition 
[Specific work to be completed] 

## Expected Output 
[Detailed description of deliverables] 

## Return Instructions 
When complete, explicitly return to Orchestrator with: 
- Summary of completed work 
- Links to deliverables 
- Issues encountered 
- Recommendations for next steps 

## Meta-Information 
- task_id: T123-456 
- origin: Orchestrator 
- destination: Research 
- boomerang_return_to: Orchestrator 
``` 

```markdown 
# Task Return (Specialist → Orchestrator) 

 
 
 
 
 
 
 
 
 
 
 
## Task Completion 
Task T123-456 has been completed. 

## Deliverables 
[Links or references to outputs] 

## Issues Encountered 
[Problems, limitations, or challenges] 

## Next Steps 
[Recommendations for follow-up work] 

## Meta-Information 
- task_id: T123-456 
- origin: Research 
- destination: Orchestrator 
- status: completed 
``` 

## Part 4: Implementation in Practice 

### Real Prompt Engineering Example: Documentation Project 

I applied these prompt engineering techniques to a documentation overhaul. Here's the actual 
flow of prompts: 

1. **Initial prompt to Orchestrator:** 
```markdown 
# Documentation Overhaul Project 

I need to completely revise our technical documentation which is outdated and inconsistently 
formatted. The documentation covers APIs, user guides, and system architecture. We need to 
ensure everything is accurate, consistently formatted, and easy to navigate. 
``` 

2. **Orchestrator decomposition prompt:** 
```markdown 
# Task Decomposition 

Apply the Strategic Planning cognitive process (Define → Infer → Synthesize) to: 

1. DEFINE the documentation project scope: 
   - What documentation components exist? 
   - What are the current issues with each? 

 
 
 
 
 
 
 
 
 
 
 
 
   - What are the quality standards for the final product? 

2. INFER the logical work breakdown: 
   - What are the natural divisions of work? 
   - What dependencies exist between components? 
   - What specialist skills are needed for each? 

3. SYNTHESIZE a project plan: 
   - Create a hierarchical task breakdown 
   - Assign specialist modes to each component 
   - Establish sequence and dependencies 
``` 

3. **Task assignment to Research Agent:** 
```markdown 
# Analyze Current Documentation State 

## Context 
We are overhauling the technical documentation that has become outdated and inconsistently 
formatted. As the Research Agent, you're responsible for analyzing the current state before we 
begin revisions. 

## Scope 
1. Inventory all existing documentation 
2. Identify inconsistencies in formatting, terminology, and structure 
3. Note outdated sections and missing information 
4. Research industry best practices for similar documentation 

## Expected Output 
Provide a comprehensive analysis document with: 
- Complete inventory with categorization 
- Gap analysis highlighting missing or outdated content 
- Identified patterns of inconsistency 
- Recommendations based on industry standards 
- Suggested prioritization for updates 

## Additional Resources 
- Documentation is located in /docs directory 
- Style guide (though often not followed) is in /docs/style-guide.md 

## Meta-Information 
- task_id: DOC-2023-001 
- assigned_to: Research 
- cognitive_process: Evidence Triangulation 

 
 
 
 
 
 
 
 
- boomerang_return_to: Orchestrator 
``` 

This approach produced dramatically better results than generic prompting. 

## Part 5: Advanced Context Management Techniques 

The "Scalpel, not Hammer" philosophy is central to my prompt engineering approach. Here's 
how it works in practice: 

1. **Progressive Loading Prompts:** 
```markdown 
I'll provide information in stages. 

STAGE 1: Essential context 
[Brief summary] 

Based on this initial context, what additional information do you need? 

STAGE 2: Supporting details (based on your answer) 
[Additional details] 

STAGE 3: Extended background (if required) 
[Comprehensive background] 
``` 

2. **Context Clearing Instructions:** 
```markdown 
After completing this task section, clear all specific implementation details from your working 
memory while retaining: 
- The high-level approach taken 
- Key decisions made 
- Interfaces with other components 

This selective clearing helps maintain overall context while freeing up tokens. 
``` 

3. **Memory Referencing Prompts:** 
```markdown 
For this task, reference stored knowledge: 
- The project structure is documented in memory_item_001 
- Previous decisions about API design are in memory_item_023 
- Code examples are stored in memory_item_047 

 
 
 
 
 
 
 
 
 
 
 
 
Apply this referenced knowledge without requesting it be repeated in full. 
``` 

## Conclusion: Building Your Own Prompt Engineering System 

The multi-agent SPARC framework demonstrates how advanced prompt engineering can 
dramatically improve AI performance. Key takeaways: 

1. **Structured templates** ensure consistent and complete information 
2. **Primitive cognitive operations** provide clear instruction patterns 
3. **Specialized agent designs** create focused expertise 
4. **Context management strategies** maximize token efficiency 
5. **Boomerang logic** ensures proper task flow 
6. **Memory systems** preserve knowledge across interactions 

This framework represents a significant evolution beyond basic prompting. By engineering a 
system of specialized prompts with clear protocols for interaction, you can achieve results that 
would be impossible with traditional approaches. 

If you're experimenting with your own prompt engineering systems, I'd love to hear what 
techniques have proven most effective for you! 

 
 
 
 
 
